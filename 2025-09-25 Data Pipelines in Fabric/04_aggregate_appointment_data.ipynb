{"cells":[{"cell_type":"markdown","source":["# 04: Aggregate Appointment Data\n","\n","In addition to the cleaning done in the previous notebook, we can also aggregate the appointment data to one line per patient. \n","\n","We do so here, creating some calculated measures of the appointments and doctors seen."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8e38b30b-ab58-4230-9303-c966bd136cee"},{"cell_type":"code","source":["%run 00_config"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dd0b8d43-5fe5-4363-aa39-5a5e5ae275f2"},{"cell_type":"code","source":["'''\n","df = spark.sql(\"SELECT * FROM coffee_lakehouse.appointment_df_clean\")\n","display(df)\n","'''"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"044ffce7-837c-48d9-9877-313c13e3ee74"},{"cell_type":"code","source":["# Read the data from the lakehouse\n","df = spark.sql(f\"\"\"\n","SELECT\n","    patient_id,\n","    -- appointment_date\n","    COUNT(DISTINCT(appointment_date)) AS count_appointments,\n","    MAX(appointment_date) AS latest_appointment,\n","    MIN(appointment_date) AS earliest_appointment,\n","    -- doctor_seen\n","    COUNT(DISTINCT(doctor_seen)) AS count_doctors_seen\n","FROM \n","    {config['lakehouse_name']}.appointment_df_clean\n","GROUP BY\n","    patient_id\n","\"\"\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7ad963e6-9e0e-48bf-a622-ae6660b5468a"},{"cell_type":"code","source":["# Save the data to the lakehouse\n","(\n","df\n","    .write\n","    .mode('overwrite')\n","    .format('delta')\n","    .option('overwriteSchema', 'true')\n","    .save(f\"{config['lakehouse_path']}/appointment_df_agg\")\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"49c56564-128e-43e7-a540-81b43eea4162"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"6d7d32eb-1533-480f-8d39-a181139f1665"},{"id":"ec5cde9a-5530-4099-ae29-d318b1970f64"}],"default_lakehouse":"ec5cde9a-5530-4099-ae29-d318b1970f64","default_lakehouse_name":"coffee_lakehouse","default_lakehouse_workspace_id":"490a35a8-ffa1-4c26-8ad2-f394ba2aaefd"}}},"nbformat":4,"nbformat_minor":5}